{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PV3jiedSIiZf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKFMPJMy5H10",
        "outputId": "129d9eae-c4e2-4dbf-fdec-71c77b29f7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ucimlrepo\n",
        "!pip3 install numpy scipy pandas matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "dataset = pd.read_csv('/content/Sver3.csv')\n",
        "\n",
        "X = dataset.iloc[:, 0:12].values\n",
        "y = dataset.iloc[:, 12].values"
      ],
      "metadata": {
        "id": "1CqC6iAGmVXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "print(y)\n",
        "print(dataset.iloc[len(X)-2,:].values)\n",
        "print(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCW38GrfspL8",
        "outputId": "c48bde0a-e846-498c-b744-26ee827be03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19579\n",
            "['EAP' 'HPL' 'EAP' ... 'EAP' 'EAP' 'HPL']\n",
            "[8 8 0 2 0.455 0.845 1.3 74 7 3 1 4.0 'EAP']\n",
            "19579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_Y = LabelEncoder()\n",
        "y = labelencoder_Y.fit_transform(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "u6fDNIPxpOq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXfj6tAqrfgg",
        "outputId": "62fa45b0-e976-4a95-fea8-a289514f4277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#classifier.add(Dropout(0.0))\n",
        "# Initialising the ANN\n",
        "\"\"\"\n",
        "初始化神經網路\n",
        "\"\"\"\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
        "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(units=3, kernel_initializer='uniform'))\n",
        "\n",
        "classifier.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "classifier.fit(X_train, y_train, batch_size = 100, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX9zZQ8mpU9Y",
        "outputId": "1d9e0f14-9633-44db-ce4a-c4bf752cc5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 2/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 3/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 4/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 5/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 6/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 7/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 8/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 9/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 10/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 11/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 12/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 13/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 14/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 15/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 16/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 17/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 18/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 19/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 20/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 21/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 22/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 23/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 24/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n",
            "Epoch 25/25\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 1.0986 - accuracy: 0.2894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ce4beb2c070>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import Accuracy\n",
        "\n",
        "# 預測\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)  # 將預測轉換為類別\n",
        "\n",
        "# 計算準確度\n",
        "accuracy = Accuracy()\n",
        "accuracy.update_state(y_test, y_pred_classes)\n",
        "result = accuracy.result()\n",
        "\n",
        "print(\"Accuracy:\", result.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVa4D2B2hq_L",
        "outputId": "37b87379-18a8-49f9-d964-87d8a40071fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123/123 [==============================] - 0s 885us/step\n",
            "Accuracy: 0.2814096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "\"\"\"\n",
        "將訓練集與測試集作標準化\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\"\"\"\n",
        "# Part 2 - Now let's make the ANN!\n",
        "\"\"\"\n",
        "建立神經網路\n",
        "\"\"\"\n",
        "# Importing the Keras libraries and packages\n",
        "\"\"\"\n",
        "匯入庫\n",
        "\"\"\"\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Initialising the ANN\n",
        "\"\"\"\n",
        "初始化神經網路\n",
        "\"\"\"\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer with dropout\n",
        "\"\"\"\n",
        "建立輸入層與第1層隱藏層\n",
        "-units = 6:隱藏層有6個神經元，通常取(輸入項+輸出項)/2\n",
        "-kernel_initializer = 'uniform':採uniform初始化權重\n",
        "-activation = 'relu':\n",
        "-input_dim = 11:輸入層有11個特徵，僅首層需要指定輸入項目數\n",
        "-Dropout(0.1):每代(epoch)該層10%神經元遮蔽，通常不會大於0.5\n",
        "\"\"\"\n",
        "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'tanh', input_dim = 13))\n",
        "#classifier.add(Dropout(0.0))\n",
        "\n",
        "# Adding the second hidden layer with dropout\n",
        "\"\"\"\n",
        "建立第2層隱藏層\n",
        "-units = 6:隱藏層有6個神經元，通常取(輸入項+輸出項)/2\n",
        "\"\"\"\n",
        "classifier.add(Dense(units = 18, kernel_initializer = 'uniform', activation = 'tanh'))\n",
        "#classifier.add(Dropout(0.0))\n",
        "\n",
        "# Adding the output layer\n",
        "\"\"\"\n",
        "建立輸出層\n",
        "-units = 1:輸出層有1個神經元。\n",
        "-kernel_initializer = 'uniform':採uniform初始化權重\n",
        "-activation = 'sigmoid':因為要算離開機率，所以採Sigmoid作為活化函數\n",
        "--如果類別大於2，則activation採Softmax\n",
        "--二元分類的輸出項固定1；多元分類(>2)則輸出項與類別相等\n",
        "\"\"\"\n",
        "classifier.add(Dense(units = 3, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "\"\"\"\n",
        "定義編譯器(Compiler)\n",
        "-optimizer = 'adam':採Adam為優化器，即權重的學習方法\n",
        "-loss = 'binary_crossentropy':採binary_crossentropy為損失函數，即誤差計算方法\n",
        "-metrics = ['accuracy']:採accuracy(正確率)規則評估模型的性能\n",
        "--二元分類採binary_crossentropy；多元分類採categorical_crossentropy\n",
        "\"\"\"\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Summarize and visualize your deep learning models\n",
        "\"\"\"\n",
        "模型架構可視化\n",
        "\"\"\"\n",
        "from keras.utils.vis_utils import plot_model\n",
        "classifier.summary()\n",
        "plot_model(classifier, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "\"\"\"\n",
        "訓練神經網路\n",
        "-X_train:訓練集特徵\n",
        "-y_train:訓練集目標\n",
        "-batch_size = 10:每10筆資料打包為1個Batch(批)\n",
        "-epochs = 100:訓練100代\n",
        "--因為8000/10 = 800，所以每1代會有800個批\n",
        "--因為batch_size大於1，所以本次為小批量梯度下降\n",
        "--accuracy: 0.8366\n",
        "\"\"\"\n",
        "classifier.fit(X_train, y_train, batch_size = 40, epochs = 100)\n",
        "\n",
        "# Part 3 - Making predictions and evaluating the model\n",
        "\"\"\"\n",
        "測試並評估神經網路\n",
        "\"\"\"\n",
        "# Predicting the Test set results\n",
        "\"\"\"\n",
        "利用測試集去測試訓練完畢的神經網路，並且將預測概率大於0.5的令為1(離開)\n",
        "--可以根據需求將閥值0.5改為任意值\n",
        "\"\"\"\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Predicting a single new observation\n",
        "\"\"\"\n",
        "用1筆自定義的客戶資料去預測他的離開率\n",
        "Predict if the customer with the following informations will leave the bank:\n",
        "Geography: France\n",
        "Credit Score: 600\n",
        "Gender: Male\n",
        "Age: 40\n",
        "Tenure: 3\n",
        "Balance: 60000\n",
        "Number of Products: 2\n",
        "Has Credit Card: Yes\n",
        "Is Active Member: Yes\n",
        "Estimated Salary: 50000\n",
        "\"\"\"\n",
        "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "\"\"\"\n",
        "利用混淆矩陣評估預測結果\n",
        "--預測誤差0.1565\n",
        "\"\"\"\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "zQA9F8iSm5pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = adult.data.features\n",
        "y = adult.data.targets\n",
        "\n",
        "# variable information\n",
        "#print(adult.variables)\n",
        "\n",
        "print(len(X))\n",
        "X.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys1ADdtq6faN",
        "outputId": "570b5bb1-2311-4dd0-ba24-433d798b49fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                 0\n",
              "workclass         963\n",
              "fnlwgt              0\n",
              "education           0\n",
              "education-num       0\n",
              "marital-status      0\n",
              "occupation        966\n",
              "relationship        0\n",
              "race                0\n",
              "sex                 0\n",
              "capital-gain        0\n",
              "capital-loss        0\n",
              "hours-per-week      0\n",
              "native-country    274\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料前處理\n"
      ],
      "metadata": {
        "id": "05YZnRQqCJsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.concat([X, y], axis=1)\n",
        "data2.info()\n",
        "data2.isna().sum()\n",
        "data=data2.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGtwiK4tAold",
        "outputId": "0a86f62a-9191-42a4-9ae0-8cd60950134a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48842 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             48842 non-null  int64 \n",
            " 1   workclass       47879 non-null  object\n",
            " 2   fnlwgt          48842 non-null  int64 \n",
            " 3   education       48842 non-null  object\n",
            " 4   education-num   48842 non-null  int64 \n",
            " 5   marital-status  48842 non-null  object\n",
            " 6   occupation      47876 non-null  object\n",
            " 7   relationship    48842 non-null  object\n",
            " 8   race            48842 non-null  object\n",
            " 9   sex             48842 non-null  object\n",
            " 10  capital-gain    48842 non-null  int64 \n",
            " 11  capital-loss    48842 non-null  int64 \n",
            " 12  hours-per-week  48842 non-null  int64 \n",
            " 13  native-country  48568 non-null  object\n",
            " 14  income          48842 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 5.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data.to_csv('Adult_ver5.csv', index=False)"
      ],
      "metadata": {
        "id": "M9CH1HcxGBFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[(data.astype(str) != '?').all(axis=1)]\n",
        "print(len(data))\n",
        "#data.to_csv('Adult_ver4.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOLsdchVCtEv",
        "outputId": "109ff510-ab27-4302-a6da-21b89d514553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 直接移除含空白的資料\n",
        "data 數量:48842=>47621"
      ],
      "metadata": {
        "id": "I6rkO_KCCeN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data2.copy()\n",
        "data=data.dropna()\n",
        "columns=data.columns\n",
        "print(len(data))\n",
        "# Remove invalid data from table\n",
        "data = data[(data.astype(str) != '?').all(axis=1)]\n",
        "len(data) # 30162"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4Y3TlA38CPU",
        "outputId": "847cfb10-309c-459c-e167-57f32053e46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45222"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data.to_csv('Adult.csv', index=False)"
      ],
      "metadata": {
        "id": "3CwWnsMoAamz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#將資料進行分組處理\n",
        "'''\n",
        "age:<30、30~40、40~50、50~60、60~70、>70\n",
        "fnlwgt:<50k、50k~100k、100k~150k、150k~200k、200k~250k、250k~300k、300k~350k、350~400k、>400k\n",
        "capital-gain:<5k、5k~10k、10k~15k、15k~20k、>20k\n",
        "capital-loss:<1k、1k~2k、2k~3k、>3k\n",
        "hours-per-week:<20、40、>60\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VCEjDZlkIh-W",
        "outputId": "2f0c2f43-daf7-4fa2-cd5d-aa46c4204b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nage:<30、30~40、40~50、50~60、60~70、>70\\nfnlwgt:<50k、50k~100k、100k~150k、150k~200k、200k~250k、250k~300k、300k~350k、350~400k、>400k\\ncapital-gain:<5k、5k~10k、10k~15k、15k~20k、>20k\\ncapital-loss:<1k、1k~2k\\nhours-per-week:<20、40、>60\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=1000\n",
        "def get_age(age):\n",
        "  if(age<30):\n",
        "    return 0\n",
        "  elif((age>=30)and(age<40)):\n",
        "    return 1\n",
        "  elif((age>=40)and(age<50)):\n",
        "    return 2\n",
        "  elif((age>=50)and(age<60)):\n",
        "    return 3\n",
        "  elif((age>=60)and(age<70)):\n",
        "    return 4\n",
        "  elif(age>=70):\n",
        "    return 5\n",
        "def get_fnlwgt(fnlwgt):\n",
        "  if(fnlwgt<50*k):\n",
        "    return 0\n",
        "  elif((fnlwgt>=50*k)and(fnlwgt<100*k)):\n",
        "    return 1\n",
        "  elif((fnlwgt>=100*k)and(fnlwgt<150*k)):\n",
        "    return 2\n",
        "  elif((fnlwgt>=150*k)and(fnlwgt<200*k)):\n",
        "    return 3\n",
        "  elif((fnlwgt>=200*k)and(fnlwgt<250*k)):\n",
        "    return 4\n",
        "  elif((fnlwgt>=250*k)and(fnlwgt<300*k)):\n",
        "    return 5\n",
        "  elif((fnlwgt>=300*k)and(fnlwgt<350*k)):\n",
        "    return 6\n",
        "  elif((fnlwgt>=350*k)and(fnlwgt<400*k)):\n",
        "    return 7\n",
        "  elif(fnlwgt>=400*k):\n",
        "    return 8\n",
        "def get_capital_gain(capital_gain):\n",
        "  if(capital_gain<5*k):\n",
        "    return 0\n",
        "  elif((capital_gain>=5*k)and(capital_gain<10*k)):\n",
        "    return 1\n",
        "  elif((capital_gain>=10*k)and(capital_gain<15*k)):\n",
        "    return 2\n",
        "  elif((capital_gain>=15*k)and(capital_gain<20*k)):\n",
        "    return 3\n",
        "  elif(capital_gain>=20*k):\n",
        "    return 4\n",
        "def get_capital_loss(capital_loss):\n",
        "  if(capital_loss<1*k):\n",
        "    return 0\n",
        "  elif((capital_loss>=1*k)and(capital_loss<2*k)):\n",
        "    return 1\n",
        "  elif((capital_loss>=2*k)and(capital_loss<3*k)):\n",
        "    return 2\n",
        "  elif(capital_loss>=3*k):\n",
        "    return 3\n",
        "def get_hours_per_week(hour):\n",
        "  if(hour<20):\n",
        "    return 0\n",
        "  elif((hour>=20)and(hour<40)):\n",
        "    return 1\n",
        "  elif((hour>=40)and(hour<60)):\n",
        "    return 2\n",
        "  elif(hour>=60):\n",
        "    return 3\n",
        "def get_ans(ans):\n",
        "  if(\"<=50K\" in ans):\n",
        "    return int(0)\n",
        "  elif(\">50K\" in ans):\n",
        "    return int(1)"
      ],
      "metadata": {
        "id": "lLz48lOWY9J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(data)):\n",
        "  data.iloc[i,0]=get_age(data.iloc[i,0])\n",
        "  data.iloc[i,2]=get_fnlwgt(data.iloc[i,2])\n",
        "  data.iloc[i,10]=get_capital_gain(data.iloc[i,10])\n",
        "  data.iloc[i,11]=get_capital_loss(data.iloc[i,11])\n",
        "  data.iloc[i,12]=get_hours_per_week(data.iloc[i,12])\n",
        "  data.iloc[i,14]=get_ans(data.iloc[i,14])\n",
        "#data.to_csv('Adult_ver2.csv', index=False)\n",
        "num_income=pd.to_numeric(data[\"income\"], downcast=\"integer\")\n",
        "data[\"income\"]=num_income"
      ],
      "metadata": {
        "id": "jXdgjTAsMvDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GmTCEAVslhP",
        "outputId": "9c11c9ef-d6af-4cb0-aed3-8b3d35675417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 45222 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             45222 non-null  int64 \n",
            " 1   workclass       45222 non-null  object\n",
            " 2   fnlwgt          45222 non-null  int64 \n",
            " 3   education       45222 non-null  object\n",
            " 4   education-num   45222 non-null  int64 \n",
            " 5   marital-status  45222 non-null  object\n",
            " 6   occupation      45222 non-null  object\n",
            " 7   relationship    45222 non-null  object\n",
            " 8   race            45222 non-null  object\n",
            " 9   sex             45222 non-null  object\n",
            " 10  capital-gain    45222 non-null  int64 \n",
            " 11  capital-loss    45222 non-null  int64 \n",
            " 12  hours-per-week  45222 non-null  int64 \n",
            " 13  native-country  45222 non-null  object\n",
            " 14  income          45222 non-null  int8  \n",
            "dtypes: int64(6), int8(1), object(8)\n",
            "memory usage: 5.2+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder  #將文字label轉成編號(int)\n",
        "le=LabelEncoder()\n",
        "non_int_list=[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\"]\n",
        "for col in non_int_list:\n",
        "  data[col]=le.fit_transform(data[col])"
      ],
      "metadata": {
        "id": "h_hQpmTBwuIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split #切分工具\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "vsy8S8RtoYb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "PredictorScaler=StandardScaler()\n",
        "X_data=data.drop(\"income\",axis=1)\n",
        "PredictorScalerFit=PredictorScaler.fit(X_data)\n",
        "X_data=PredictorScalerFit.transform(X_data)\n",
        "#X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, test_size=0.5, random_state=60)\n",
        "temp=np.array(X_train)\n",
        "X_train = torch.tensor(temp)\n",
        "y_train = torch.tensor(y_train.values)\n",
        "\n",
        "# create feature and targets tensor for test set.\n",
        "temp_test=np.array(X_test)\n",
        "X_test = torch.tensor(temp_test)\n",
        "y_test = torch.tensor(y_test.values)\n",
        "'''\n",
        "\n",
        "\n",
        "X_data=data.drop(\"income\",axis=1)\n",
        "import torch\n",
        "\n",
        "X = torch.tensor(X_data.values, dtype=torch.float32)\n",
        "y = torch.tensor(data[\"income\"], dtype=torch.float32).reshape(-1, 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=40)"
      ],
      "metadata": {
        "id": "rp4MR0GqpvS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size, epoch and iteration\n",
        "batch_size = 100\n",
        "n_iters = len(data)\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "# Pytorch train and test sets\n",
        "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "\n",
        "# data loader\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "Ic1G0O2F9uZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "H8Zw9hBczlc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ANN Model\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# instantiate ANN\n",
        "input_dim = 14\n",
        "hidden_dim = 42\n",
        "output_dim = 1\n",
        "\n",
        "# Create ANN\n",
        "model = ANNModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# binary cross entropy\n",
        "error = nn.BCELoss()\n",
        "\n",
        "# Adam Optimizer\n",
        "optimizer_A = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "P4o1GXik8jGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "\n",
        "def model_train(model, X_train, y_train, X_val, y_val):\n",
        "    # loss function and optimizer\n",
        "    loss_fn = error  # binary cross entropy\n",
        "    optimizer = optimizer_A\n",
        "\n",
        "    n_epochs = 150   # number of epochs to run\n",
        "    batch_size = 20  # size of each batch\n",
        "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
        "\n",
        "    # Hold the best model\n",
        "    best_acc = - np.inf   # init to negative infinity\n",
        "    best_weights = None\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
        "            bar.set_description(f\"Epoch {epoch}\")\n",
        "            for start in bar:\n",
        "                # take a batch\n",
        "                X_batch = X_train[start:start+batch_size]\n",
        "                y_batch = y_train[start:start+batch_size]\n",
        "                # forward pass\n",
        "                y_pred = model(X_batch)\n",
        "                loss = loss_fn(y_pred, y_batch)\n",
        "                # backward pass\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                # update weights\n",
        "                optimizer.step()\n",
        "                # print progress\n",
        "                acc = (y_pred.round() == y_batch).float().mean()\n",
        "                bar.set_postfix(\n",
        "                    loss=float(loss),\n",
        "                    acc=float(acc)\n",
        "                )\n",
        "        # evaluate accuracy at end of each epoch\n",
        "        model.eval()\n",
        "        y_pred = model(X_val)\n",
        "        acc = (y_pred.round() == y_val).float().mean()\n",
        "        acc = float(acc)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "    # restore model and return best accuracy\n",
        "    model.load_state_dict(best_weights)\n",
        "    return best_acc"
      ],
      "metadata": {
        "id": "oZdcKhDL9VqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "# train-test split: Hold out the test set for final model evaluation\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# define 5-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "cv_scores_wide = []\n",
        "for train, test in kfold.split(X_train, y_train):\n",
        "    # create model, train, and get accuracy\n",
        "    model = ANNModel(input_dim,hidden_dim,output_dim)\n",
        "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
        "    print(\"Accuracy: %.2f\" % acc)\n",
        "    cv_scores_wide.append(acc)\n",
        "\n",
        "# evaluate the model\n",
        "acc = np.mean(cv_scores_wide)\n",
        "std = np.std(cv_scores_wide)\n",
        "print(\"Wide: %.2f%% (+/- %.2f%%)\" % (acc*100, std*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwaO4Z_6B-zo",
        "outputId": "574567df-69b4-4578-a15a-46d7aa3faa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.24\n",
            "Accuracy: 0.76\n",
            "Accuracy: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANNModel(input_dim,hidden_dim,output_dim)\n",
        "acc = model_train(model, X_train, y_train, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "rLrT6n6_dUxA",
        "outputId": "2f07769c-1821-4d39-dc21-41e73c3e1f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a1b15f21b274>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-b84896ed8eda>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(model, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-12ab6ad91983>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20x14 and 1x42)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 沒用到的code"
      ],
      "metadata": {
        "id": "PV3jiedSIiZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.iloc[13933,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT34yEjpXXQj",
        "outputId": "c1ef1419-44b8-47ff-db08-140942c300c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                               23\n",
            "workclass                          ?\n",
            "fnlwgt                        226891\n",
            "education                    HS-grad\n",
            "education-num                      9\n",
            "marital-status         Never-married\n",
            "occupation                         ?\n",
            "relationship          Other-relative\n",
            "race              Asian-Pac-Islander\n",
            "sex                           Female\n",
            "capital-gain                       0\n",
            "capital-loss                       0\n",
            "hours-per-week                    20\n",
            "native-country                 South\n",
            "income                         <=50K\n",
            "Name: 13933, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"income\"].unique().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgglmWViZef6",
        "outputId": "32587895-889d-4423-a85c-c591e719364d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<=50K', '>50K', '<=50K.', '>50K.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=data.columns\n",
        "all_types=data.dtypes\n",
        "change_type=[]\n",
        "#print(all_types)\n",
        "for i in all_types:\n",
        "  if(i==int):\n",
        "    change_type.append(0)\n",
        "  else:\n",
        "    change_type.append(1)\n",
        "for i in range(0,len(columns)):\n",
        "  if(change_type[i]):   #需要轉換data type\n",
        "    column_name=columns[i]\n",
        "    temp=data[column_name].unique().tolist()\n",
        "    temp_value=[]\n",
        "    print(temp)\n",
        "    print(column_name)\n",
        "    number_data=len(data)\n",
        "    for j in range(0,number_data):\n",
        "      for k in range(0,len(temp)):\n",
        "        if(data.iloc[j,i]==temp[k]):\n",
        "          temp_value.append(k)\n",
        "    data[column_name]=temp_value.copy()\n",
        "    temp_value.clear()\n",
        "print(len(data))\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-omDfP6Pg_TG",
        "outputId": "9f66d73d-bfc5-4496-e6ee-791214075b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', 'Self-emp-inc', 'Without-pay']\n",
            "workclass\n",
            "['Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', '7th-8th', 'Doctorate', 'Assoc-voc', 'Prof-school', '5th-6th', '10th', 'Preschool', '12th', '1st-4th']\n",
            "education\n",
            "['Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed']\n",
            "marital-status\n",
            "['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners', 'Prof-specialty', 'Other-service', 'Sales', 'Transport-moving', 'Farming-fishing', 'Machine-op-inspct', 'Tech-support', 'Craft-repair', 'Protective-serv', 'Armed-Forces', 'Priv-house-serv']\n",
            "occupation\n",
            "['Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative']\n",
            "relationship\n",
            "['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other']\n",
            "race\n",
            "['Male', 'Female']\n",
            "sex\n",
            "['United-States', 'Cuba', 'Jamaica', 'India', 'Mexico', 'Puerto-Rico', 'Honduras', 'England', 'Canada', 'Germany', 'Iran', 'Philippines', 'Poland', 'Columbia', 'Cambodia', 'Thailand', 'Ecuador', 'Laos', 'Taiwan', 'Haiti', 'Portugal', 'Dominican-Republic', 'El-Salvador', 'France', 'Guatemala', 'Italy', 'China', 'South', 'Japan', 'Yugoslavia', 'Peru', 'Outlying-US(Guam-USVI-etc)', 'Scotland', 'Trinadad&Tobago', 'Greece', 'Nicaragua', 'Vietnam', 'Hong', 'Ireland', 'Hungary', 'Holand-Netherlands']\n",
            "native-country\n",
            "['<=50K', '>50K', '<=50K.', '>50K.']\n",
            "income\n",
            "45222\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 45222 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   age             45222 non-null  int64\n",
            " 1   workclass       45222 non-null  int64\n",
            " 2   fnlwgt          45222 non-null  int64\n",
            " 3   education       45222 non-null  int64\n",
            " 4   education-num   45222 non-null  int64\n",
            " 5   marital-status  45222 non-null  int64\n",
            " 6   occupation      45222 non-null  int64\n",
            " 7   relationship    45222 non-null  int64\n",
            " 8   race            45222 non-null  int64\n",
            " 9   sex             45222 non-null  int64\n",
            " 10  capital-gain    45222 non-null  int64\n",
            " 11  capital-loss    45222 non-null  int64\n",
            " 12  hours-per-week  45222 non-null  int64\n",
            " 13  native-country  45222 non-null  int64\n",
            " 14  income          45222 non-null  int64\n",
            "dtypes: int64(15)\n",
            "memory usage: 5.5 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns=data.columns\n",
        "all_types=data.dtypes\n",
        "change_type=[]\n",
        "#print(all_types)\n",
        "for i in all_types:\n",
        "  if(i==int):\n",
        "    change_type.append(0)\n",
        "  else:\n",
        "    change_type.append(1)\n",
        "#print(change_type)len(columns)\n",
        "drop_data=[]\n",
        "for i in range(0,len(columns)):\n",
        "  if(change_type[i]):   #需要轉換data type\n",
        "    column_name=columns[i]\n",
        "    temp=data[column_name].unique().tolist()\n",
        "    temp_value=[]\n",
        "    print(temp)\n",
        "    print(column_name)\n",
        "    number_data=len(data)\n",
        "    for j in range(0,number_data):\n",
        "      for k in range(0,len(temp)):\n",
        "        if((data.iloc[j,i]==temp[k])and(temp[k]!='?')):\n",
        "          temp_value.append(k)\n",
        "        elif((data.iloc[j,i]==temp[k])and(temp[k]=='?')):\n",
        "          temp_value.append(k)\n",
        "          drop_data.append(j)\n",
        "    data[column_name]=temp_value.copy()\n",
        "    temp_value.clear()\n",
        "    #drop_data.clear()\n",
        "    #print(temp_value)\n",
        "    #print(drop_data)\n",
        "drop_data=list(set(drop_data))\n",
        "for m in drop_data:\n",
        "  data.drop(m,inplace=True)\n",
        "print(len(data))\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_rnRQNXCI5l",
        "outputId": "d7c8ff57-08f6-427b-ea4f-a7e0eef72407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
            "workclass\n",
            "['Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th']\n",
            "education\n",
            "['Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed']\n",
            "marital-status\n",
            "['Adm-clerical', 'Exec-managerial', 'Handlers-cleaners', 'Prof-specialty', 'Other-service', 'Sales', 'Craft-repair', 'Transport-moving', 'Farming-fishing', 'Machine-op-inspct', 'Tech-support', '?', 'Protective-serv', 'Armed-Forces', 'Priv-house-serv']\n",
            "occupation\n",
            "['Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative']\n",
            "relationship\n",
            "['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other']\n",
            "race\n",
            "['Male', 'Female']\n",
            "sex\n",
            "['United-States', 'Cuba', 'Jamaica', 'India', '?', 'Mexico', 'South', 'Puerto-Rico', 'Honduras', 'England', 'Canada', 'Germany', 'Iran', 'Philippines', 'Italy', 'Poland', 'Columbia', 'Cambodia', 'Thailand', 'Ecuador', 'Laos', 'Taiwan', 'Haiti', 'Portugal', 'Dominican-Republic', 'El-Salvador', 'France', 'Guatemala', 'China', 'Japan', 'Yugoslavia', 'Peru', 'Outlying-US(Guam-USVI-etc)', 'Scotland', 'Trinadad&Tobago', 'Greece', 'Nicaragua', 'Vietnam', 'Hong', 'Ireland', 'Hungary', 'Holand-Netherlands']\n",
            "native-country\n",
            "['<=50K', '>50K', '<=50K.', '>50K.']\n",
            "income\n",
            "45222\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 45222 entries, 0 to 48841\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   age             45222 non-null  int64\n",
            " 1   workclass       45222 non-null  int64\n",
            " 2   fnlwgt          45222 non-null  int64\n",
            " 3   education       45222 non-null  int64\n",
            " 4   education-num   45222 non-null  int64\n",
            " 5   marital-status  45222 non-null  int64\n",
            " 6   occupation      45222 non-null  int64\n",
            " 7   relationship    45222 non-null  int64\n",
            " 8   race            45222 non-null  int64\n",
            " 9   sex             45222 non-null  int64\n",
            " 10  capital-gain    45222 non-null  int64\n",
            " 11  capital-loss    45222 non-null  int64\n",
            " 12  hours-per-week  45222 non-null  int64\n",
            " 13  native-country  45222 non-null  int64\n",
            " 14  income          45222 non-null  int64\n",
            "dtypes: int64(15)\n",
            "memory usage: 5.5 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icome_Correction=[]\n",
        "for i in range(0,len(data)):\n",
        "  if(data.iloc[i,14]%2):\n",
        "    icome_Correction.append(1)\n",
        "  else:\n",
        "    icome_Correction.append(0)\n",
        "data['income']=icome_Correction.copy()"
      ],
      "metadata": {
        "id": "LLwxHvq5a0cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"income\"].unique().tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGVRP7x9Rrz9",
        "outputId": "dfb650f0-8420-453c-c3f6-fb2d4badd1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1]\n"
          ]
        }
      ]
    }
  ]
}